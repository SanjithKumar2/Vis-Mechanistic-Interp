{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c9ec0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\miniconda3\\envs\\xformers-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from timm.models.vision_transformer import VisionTransformer\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.fx import symbolic_trace\n",
    "from torch.autograd import Function\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import timm\n",
    "import json\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3600c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "imagenet_labels = urllib.request.urlopen(url).read().decode(\"utf-8\").splitlines()\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "m = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2aaf2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a sample image\n",
    "url = \"https://github.com/pytorch/hub/raw/master/images/dog.jpg\"\n",
    "image = Image.open(BytesIO(requests.get(url).content)).convert(\"RGB\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225)\n",
    "    ),\n",
    "])\n",
    "x = transform(image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb919798",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d00feaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = []\n",
    "def forward_hook(module,input,output):\n",
    "    activations.append(input)\n",
    "handle = model.head.register_forward_hook(forward_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "43655eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def linear_lrp(R_out, module, output, activation, eps=1e-8, **kwargs):\n",
    "    W = module.weight\n",
    "    S = R_out/(output + eps)\n",
    "    numen = activation[:,:,None] * W.T[None,:,:]\n",
    "    R_in = numen*S[:,None,:]\n",
    "    return R_in.sum(-1)\n",
    "@torch.no_grad\n",
    "def identity_lrp(R_out, **kwargs):\n",
    "    return R_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9469ac55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d40a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = torch.zeros_like(y)\n",
    "R[0,torch.argmax(y)] = y[0,torch.argmax(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8e82ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ = linear_lrp(R,model.head,y,activations[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b7a71b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = R_.squeeze(0).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f38de808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.bar(range(len(P)), P)\n",
    "plt.title(\"Relevance of Linear Layer (fc1)\")\n",
    "plt.xlabel(\"Neuron index\")\n",
    "plt.ylabel(\"Relevance value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77695804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <class 'timm.models.vision_transformer.VisionTransformer'>\n",
      "patch_embed <class 'timm.layers.patch_embed.PatchEmbed'>\n",
      "patch_embed.proj <class 'torch.nn.modules.conv.Conv2d'>\n",
      "patch_embed.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "pos_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "patch_drop <class 'torch.nn.modules.linear.Identity'>\n",
      "norm_pre <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks <class 'torch.nn.modules.container.Sequential'>\n",
      "blocks.0 <class 'timm.models.vision_transformer.Block'>\n",
      "blocks.0.norm1 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.0.attn <class 'timm.layers.attention.Attention'>\n",
      "blocks.0.attn.qkv <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.0.attn.q_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.0.attn.k_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.0.attn.attn_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.0.attn.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.0.attn.proj <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.0.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.0.ls1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.0.drop_path1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.0.norm2 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.0.mlp <class 'timm.layers.mlp.Mlp'>\n",
      "blocks.0.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.0.mlp.act <class 'torch.nn.modules.activation.GELU'>\n",
      "blocks.0.mlp.drop1 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.0.mlp.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.0.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.0.mlp.drop2 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.0.ls2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.0.drop_path2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.1 <class 'timm.models.vision_transformer.Block'>\n",
      "blocks.1.norm1 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.1.attn <class 'timm.layers.attention.Attention'>\n",
      "blocks.1.attn.qkv <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.1.attn.q_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.1.attn.k_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.1.attn.attn_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.1.attn.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.1.attn.proj <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.1.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.1.ls1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.1.drop_path1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.1.norm2 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.1.mlp <class 'timm.layers.mlp.Mlp'>\n",
      "blocks.1.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.1.mlp.act <class 'torch.nn.modules.activation.GELU'>\n",
      "blocks.1.mlp.drop1 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.1.mlp.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.1.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.1.mlp.drop2 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.1.ls2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.1.drop_path2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.2 <class 'timm.models.vision_transformer.Block'>\n",
      "blocks.2.norm1 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.2.attn <class 'timm.layers.attention.Attention'>\n",
      "blocks.2.attn.qkv <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.2.attn.q_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.2.attn.k_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.2.attn.attn_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.2.attn.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.2.attn.proj <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.2.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.2.ls1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.2.drop_path1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.2.norm2 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.2.mlp <class 'timm.layers.mlp.Mlp'>\n",
      "blocks.2.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.2.mlp.act <class 'torch.nn.modules.activation.GELU'>\n",
      "blocks.2.mlp.drop1 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.2.mlp.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.2.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.2.mlp.drop2 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.2.ls2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.2.drop_path2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.3 <class 'timm.models.vision_transformer.Block'>\n",
      "blocks.3.norm1 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.3.attn <class 'timm.layers.attention.Attention'>\n",
      "blocks.3.attn.qkv <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.3.attn.q_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.3.attn.k_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.3.attn.attn_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.3.attn.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.3.attn.proj <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.3.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.3.ls1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.3.drop_path1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.3.norm2 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.3.mlp <class 'timm.layers.mlp.Mlp'>\n",
      "blocks.3.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.3.mlp.act <class 'torch.nn.modules.activation.GELU'>\n",
      "blocks.3.mlp.drop1 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.3.mlp.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.3.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.3.mlp.drop2 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.3.ls2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.3.drop_path2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.4 <class 'timm.models.vision_transformer.Block'>\n",
      "blocks.4.norm1 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.4.attn <class 'timm.layers.attention.Attention'>\n",
      "blocks.4.attn.qkv <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.4.attn.q_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.4.attn.k_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.4.attn.attn_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.4.attn.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.4.attn.proj <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.4.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.4.ls1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.4.drop_path1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.4.norm2 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.4.mlp <class 'timm.layers.mlp.Mlp'>\n",
      "blocks.4.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.4.mlp.act <class 'torch.nn.modules.activation.GELU'>\n",
      "blocks.4.mlp.drop1 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.4.mlp.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.4.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.4.mlp.drop2 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.4.ls2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.4.drop_path2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.5 <class 'timm.models.vision_transformer.Block'>\n",
      "blocks.5.norm1 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.5.attn <class 'timm.layers.attention.Attention'>\n",
      "blocks.5.attn.qkv <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.5.attn.q_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.5.attn.k_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.5.attn.attn_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.5.attn.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.5.attn.proj <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.5.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.5.ls1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.5.drop_path1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.5.norm2 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.5.mlp <class 'timm.layers.mlp.Mlp'>\n",
      "blocks.5.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.5.mlp.act <class 'torch.nn.modules.activation.GELU'>\n",
      "blocks.5.mlp.drop1 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.5.mlp.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.5.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.5.mlp.drop2 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.5.ls2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.5.drop_path2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.6 <class 'timm.models.vision_transformer.Block'>\n",
      "blocks.6.norm1 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.6.attn <class 'timm.layers.attention.Attention'>\n",
      "blocks.6.attn.qkv <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.6.attn.q_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.6.attn.k_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.6.attn.attn_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.6.attn.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.6.attn.proj <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.6.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.6.ls1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.6.drop_path1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.6.norm2 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.6.mlp <class 'timm.layers.mlp.Mlp'>\n",
      "blocks.6.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.6.mlp.act <class 'torch.nn.modules.activation.GELU'>\n",
      "blocks.6.mlp.drop1 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.6.mlp.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.6.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.6.mlp.drop2 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.6.ls2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.6.drop_path2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.7 <class 'timm.models.vision_transformer.Block'>\n",
      "blocks.7.norm1 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.7.attn <class 'timm.layers.attention.Attention'>\n",
      "blocks.7.attn.qkv <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.7.attn.q_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.7.attn.k_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.7.attn.attn_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.7.attn.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.7.attn.proj <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.7.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.7.ls1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.7.drop_path1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.7.norm2 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.7.mlp <class 'timm.layers.mlp.Mlp'>\n",
      "blocks.7.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.7.mlp.act <class 'torch.nn.modules.activation.GELU'>\n",
      "blocks.7.mlp.drop1 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.7.mlp.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.7.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.7.mlp.drop2 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.7.ls2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.7.drop_path2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.8 <class 'timm.models.vision_transformer.Block'>\n",
      "blocks.8.norm1 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.8.attn <class 'timm.layers.attention.Attention'>\n",
      "blocks.8.attn.qkv <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.8.attn.q_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.8.attn.k_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.8.attn.attn_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.8.attn.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.8.attn.proj <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.8.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.8.ls1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.8.drop_path1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.8.norm2 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.8.mlp <class 'timm.layers.mlp.Mlp'>\n",
      "blocks.8.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.8.mlp.act <class 'torch.nn.modules.activation.GELU'>\n",
      "blocks.8.mlp.drop1 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.8.mlp.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.8.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.8.mlp.drop2 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.8.ls2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.8.drop_path2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.9 <class 'timm.models.vision_transformer.Block'>\n",
      "blocks.9.norm1 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.9.attn <class 'timm.layers.attention.Attention'>\n",
      "blocks.9.attn.qkv <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.9.attn.q_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.9.attn.k_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.9.attn.attn_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.9.attn.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.9.attn.proj <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.9.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.9.ls1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.9.drop_path1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.9.norm2 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.9.mlp <class 'timm.layers.mlp.Mlp'>\n",
      "blocks.9.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.9.mlp.act <class 'torch.nn.modules.activation.GELU'>\n",
      "blocks.9.mlp.drop1 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.9.mlp.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.9.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.9.mlp.drop2 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.9.ls2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.9.drop_path2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.10 <class 'timm.models.vision_transformer.Block'>\n",
      "blocks.10.norm1 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.10.attn <class 'timm.layers.attention.Attention'>\n",
      "blocks.10.attn.qkv <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.10.attn.q_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.10.attn.k_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.10.attn.attn_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.10.attn.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.10.attn.proj <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.10.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.10.ls1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.10.drop_path1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.10.norm2 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.10.mlp <class 'timm.layers.mlp.Mlp'>\n",
      "blocks.10.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.10.mlp.act <class 'torch.nn.modules.activation.GELU'>\n",
      "blocks.10.mlp.drop1 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.10.mlp.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.10.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.10.mlp.drop2 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.10.ls2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.10.drop_path2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.11 <class 'timm.models.vision_transformer.Block'>\n",
      "blocks.11.norm1 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.11.attn <class 'timm.layers.attention.Attention'>\n",
      "blocks.11.attn.qkv <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.11.attn.q_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.11.attn.k_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.11.attn.attn_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.11.attn.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.11.attn.proj <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.11.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.11.ls1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.11.drop_path1 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.11.norm2 <class 'timm.layers.norm.LayerNorm'>\n",
      "blocks.11.mlp <class 'timm.layers.mlp.Mlp'>\n",
      "blocks.11.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.11.mlp.act <class 'torch.nn.modules.activation.GELU'>\n",
      "blocks.11.mlp.drop1 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.11.mlp.norm <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.11.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>\n",
      "blocks.11.mlp.drop2 <class 'torch.nn.modules.dropout.Dropout'>\n",
      "blocks.11.ls2 <class 'torch.nn.modules.linear.Identity'>\n",
      "blocks.11.drop_path2 <class 'torch.nn.modules.linear.Identity'>\n",
      "norm <class 'timm.layers.norm.LayerNorm'>\n",
      "fc_norm <class 'torch.nn.modules.linear.Identity'>\n",
      "head_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
      "head <class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(name, type(module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfbaea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class epsilon_lrp_fn(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, fn, epsilon, *inputs):\n",
    "\n",
    "        # create boolean mask for inputs requiring gradients\n",
    "        #TODO: use ctx.needs_input_grad instead of requires_grad\n",
    "        requires_grads = [True if inp.requires_grad else False for inp in inputs]\n",
    "        if sum(requires_grads) == 0:\n",
    "            # no gradients to compute or gradient checkpointing is used\n",
    "            return fn(*inputs)\n",
    "        \n",
    "        # detach inputs to avoid overwriting gradients if same input is used as multiple arguments (like in self-attention)\n",
    "        inputs = tuple(inp.detach().requires_grad_() if inp.requires_grad else inp for inp in inputs)\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            outputs = fn(*inputs)\n",
    "\n",
    "        ctx.epsilon, ctx.requires_grads = epsilon, requires_grads\n",
    "        # save only inputs requiring gradients\n",
    "        inputs = tuple(inputs[i] for i in range(len(inputs)) if requires_grads[i])\n",
    "        ctx.save_for_backward(*inputs, outputs)\n",
    "        \n",
    "        return outputs.detach()\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, *out_relevance):\n",
    "\n",
    "        inputs, outputs = ctx.saved_tensors[:-1], ctx.saved_tensors[-1]\n",
    "        relevance_norm = out_relevance[0] / _stabilize(outputs, ctx.epsilon, inplace=False)\n",
    "\n",
    "        # computes vector-jacobian product\n",
    "        grads = torch.autograd.grad(outputs, inputs, relevance_norm)\n",
    "\n",
    "        # return relevance at requires_grad indices else None\n",
    "        relevance = iter([grads[i].mul_(inputs[i]) for i in range(len(inputs))])\n",
    "        return (None, None) + tuple(next(relevance) if req_grad else None for req_grad in ctx.requires_grads)\n",
    "class identity_fn(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, fn, input):\n",
    "\n",
    "        output = fn(input)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, *out_relevance):\n",
    "        return (None,) + out_relevance\n",
    "\n",
    "class softmax_fn(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(cache, inputs, dim, temprature=1.0, dtype=None, inplace=False):\n",
    "        if dtype is not None:\n",
    "            inputs = inputs.to(dtype)\n",
    "        inputs = inputs/temprature\n",
    "        outputs = F.softmax(inputs, dim=dim, dtype=dtype)\n",
    "\n",
    "        cache.save_for_backward(inputs, outputs)\n",
    "        cache.inplace=inplace\n",
    "        return outputs\n",
    "    @staticmethod\n",
    "    def backward(cache, *R_out):\n",
    "        inputs, outputs = cache.saved_tensors\n",
    "        R_out = R_out[0]\n",
    "        inputs = torch.where(torch.isneginf(inputs),torch.tensor(0).to(inputs), inputs)\n",
    "        if cache.inplace:\n",
    "            R_in = (R_out.sub_(outputs.mul_(R_out.sum(-1, keepdim=True)))).mul_(inputs)\n",
    "        else:\n",
    "            R_in = inputs * (R_out - outputs * R_out.sum(-1, keepdim=True))\n",
    "        return (R_in, None, None, None, None)\n",
    "\n",
    "class linear_fn(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(cache, inputs, weight, bias, epsilon=1e-8):\n",
    "        outputs = F.linear(inputs, weight, bias)\n",
    "        cache.save_for_backward(inputs, outputs, weight)\n",
    "        cache.epsilon = epsilon\n",
    "        return outputs\n",
    "    @staticmethod\n",
    "    def backward(cache, *R_out):\n",
    "        inputs, outputs, weight = cache.saved_tensors\n",
    "        R_out = R_out[0]\n",
    "        S = R_out/outputs.add_(cache.epsilon)\n",
    "        R_in = torch.matmul(S, weight).mul_(inputs)\n",
    "        return (R_in, None, None, None)\n",
    "\n",
    "class matmul_fn(Function):\n",
    "    '''This is LRP bkwd for Attn matmul between A (softmax(Q.(K.T)/sqrt(dim))) and V (value vector), don't confuse with linear ops between input and weight matrix'''\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(cache, input_a, input_b, epsilon=1e-12, inplace=False):\n",
    "        output = torch.matmul(input_a, input_b)\n",
    "        cache.save_for_backward(input_a, input_b, output)\n",
    "        cache.epsilon=epsilon\n",
    "        cache.inplace = inplace\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(cache, *R_out):\n",
    "        R_out = R_out[0]\n",
    "        input_a, input_b, output = cache.saved_tensors\n",
    "        epsilon, inplace = cache.epsilon, cache.inplace\n",
    "        if inplace:\n",
    "            S = R_out.div_(output.mul_(2).add_(epsilon))\n",
    "        else:\n",
    "            S = R_out / ((2*output)+epsilon)\n",
    "        R_ina = torch.matmul(S, input_b.T).mul_(input_a)\n",
    "        R_inb = torch.matmul(input_a.T, S).mul_(inbut_b)\n",
    "        return (R_ina, R_inb, None, None)\n",
    "\n",
    "class add_2_tensors_fn(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(cache, input_a, input_b, inplace=False, epsilon=1e-8):\n",
    "        outputs = input_a + input_b\n",
    "        cache.requires_grads = [i for i, inp in enumerate((input_a, input_b)) if isinstance(inp, torch.Tensor) and inp.requires_grad]\n",
    "        if input_a.requires_grad or input_b.requires_grad:\n",
    "            cache.save_for_backward(input_a, input_b)\n",
    "            cache.inplace=inplace\n",
    "            cache.epsilon = epsilon\n",
    "        return outputs\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(cache, *R_out):\n",
    "        if not cache.requires_grads:\n",
    "            return (None, None, None, None)\n",
    "        input_a, input_b = cache.saved_tensors\n",
    "        R_out = R_out[0]\n",
    "        epsilon = cache.epsilon\n",
    "        if cache.inplace:\n",
    "            R_ina = (R_out * input_a).div_(input_a+input_b+epsilon)\n",
    "            R_inb = R_out.mul_(input_b).div_(input_a+input_b+epsilon)\n",
    "        else:\n",
    "            R_ina = (R_out * input_a).div_(input_a+input_b+epsilon)\n",
    "            R_inb = (R_out * input_b).div_(input_a+input_b+epsilon)\n",
    "        return (R_ina if 0 in cache.requires_grads else None, R_inb if 1 in cache.requires_grads else None, None, None)\n",
    "\n",
    "class mul2_fn(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(cache, input_a, input_b, inplace=False):\n",
    "\n",
    "        cache.requires_grads = [i for i, inp in enumerate((input_a, input_b)) if isinstance(inp, torch.Tensor) and inp.requires_grad]\n",
    "        cache.inplace = inplace\n",
    "\n",
    "        return input_a * input_b\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(cache, *R_out):\n",
    "\n",
    "        n = len(cache.requires_grads)\n",
    "        R_out = R_out[0]\n",
    "        if cache.inplace:\n",
    "            R_in = R_out.div_(n)\n",
    "        else:\n",
    "            R_in = R_out / n\n",
    "        return tuple(R_in if i in ctx.requires_grads else None for i in range(2)) + (None,)\n",
    "\n",
    "class layernorm_fn(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(cache, input, weight, bias, epsilon=1e-6, var_epsilon=1e-6):\n",
    "        \n",
    "        with torch.enable_grad():\n",
    "\n",
    "            mean = input.mean(-1, keepdim=True)\n",
    "            var = ((input - mean)**2).mean(-1, keepdim=True)\n",
    "            std = (var + var_epsilon).sqrt()\n",
    "            y = (input-mean)/std.detach()\n",
    "            y = y * weight + bias\n",
    "\n",
    "            cache.save_for_backward(input, y)\n",
    "            cache.epsilon = epsilon\n",
    "        \n",
    "        return y.detach()\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(cache, *R_out):\n",
    "        x, y = cache.saved_tensors\n",
    "\n",
    "        R_out = R_out[0]\n",
    "        R_norm = R_out/ (y + cache.epsilon)\n",
    "        grads = torch.autograd.grad(y, x, R_norm)\n",
    "        R_in = grads*x\n",
    "        return (R_in, None, None, None, None)\n",
    "\n",
    "class conv_fn(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(cache, inputs, module,lowest=0., highest=1.):\n",
    "        output = module(inputs)\n",
    "        cache.stride, cache.padding, cache.kernel, cache.lowest, cache.highest = module.stride, module.padding, module.kernel_size, lowest, highest\n",
    "        cache.save_for_backward(inputs, output, module.weight)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(cache, *R_out):\n",
    "        R = R_out[0]\n",
    "        stride, padding, kernel, lowest, highest = cache.stride, cache.padding, cache.kernel, cache.lowest, cache.highest\n",
    "        activation, Z_O, weight = cache.saved_tensors\n",
    "        output_padding = activation.size(2) - ((R.size(2) - 1) * stride[0] \\\n",
    "                                                - 2 * padding[0] + kernel[0])\n",
    "        W_L = torch.clamp(weight, min=0)\n",
    "        W_H = torch.clamp(weight, max=0)\n",
    "\n",
    "        L = torch.ones_like(activation, dtype=activation.dtype) * lowest\n",
    "        H = torch.ones_like(activation, dtype=activation.dtype) * highest\n",
    "        Z_L = F.conv2d(L, W_L, stride=stride, padding=padding)\n",
    "        Z_H = F.conv2d(H, W_H, stride=stride, padding=padding)\n",
    "        Z = Z_O - Z_L - Z_H + 1e-9\n",
    "        S = R / Z\n",
    "\n",
    "        C_O = F.conv_transpose2d(S, module.weight, stride=stride, padding=padding, output_padding=output_padding)\n",
    "        C_L = F.conv_transpose2d(S, W_L, stride=stride, padding=padding, output_padding=output_padding)\n",
    "        C_H = F.conv_transpose2d(S, W_H, stride=stride, padding=padding, output_padding=output_padding)\n",
    "\n",
    "        R_in = activation * C_O - L * C_L - H * C_H\n",
    "\n",
    "        return (R_in, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "166bfd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.fx.wrap\n",
    "def softmax(inputs, dim, temprature=1.0, dtype=None, inplace=False):\n",
    "    return softmax_fn.apply(inputs, dim, temprature=1.0, dtype=None, inplace=False)\n",
    "\n",
    "@torch.fx.wrap\n",
    "def linear(module, inputs, epsilon=1e-8):\n",
    "    return linear_fn.apply(inputs, module.weight, module.bias, epsilon)\n",
    "\n",
    "@torch.fx.wrap\n",
    "def matmul(input_a, input_b, epsilon=1e-12, inplace=False):\n",
    "    return matmul_fn.apply(input_a, input_b, epsilon=1e-12, inplace=False)\n",
    "\n",
    "@torch.fx.wrap\n",
    "def add(input_a, input_b, inplace=False, epsilon=1e-8):\n",
    "    return matmul_fn.apply(input_a, input_b, inplace=False, epsilon=1e-8)\n",
    "\n",
    "@torch.fx.wrap\n",
    "def mul(input_a, input_b, inplace=False):\n",
    "    return mul2_fn.apply(input_a, input_b, inplace=False)\n",
    "\n",
    "@torch.fx.wrap\n",
    "def layernorm(module, input, epsilon=1e-6, var_epsilon=1e-6):\n",
    "    return layernorm_fn.apply(input, module.weight, module.bias, epsilon=1e-6, var_epsilon=1e-6)\n",
    "\n",
    "@torch.fx.wrap\n",
    "def identity(fn, input):\n",
    "    return identity_fn.apply(fn, input)\n",
    "\n",
    "@torch.fx.wrap\n",
    "def epsilon_lrp(fn, epsilon, *inputs):\n",
    "    return epsilon_lrp_fn.apply(fn, epsilon, *inputs)\n",
    "\n",
    "@torch.fx.wrap\n",
    "def conv_2d(fn, inputs):\n",
    "    return conv_fn.apply(inputs,fn)\n",
    "\n",
    "@torch.fx.wrap\n",
    "def multihead_attn_fn_cp(dim: int,\n",
    "        x,\n",
    "        qkv,\n",
    "        q_norm,\n",
    "        k_norm,\n",
    "        attn_drop,\n",
    "        norm,\n",
    "        proj,\n",
    "        proj_drop,\n",
    "        num_heads: int = 8,\n",
    "        attn_mask=None):\n",
    "\n",
    "        assert dim%num_heads==0, 'dim should be divisible by num_heads'\n",
    "        if qk_norm or scale_norm:\n",
    "            assert norm_layer is not None, 'norm_layer must be provided if qk_norm or scale_norm is True'\n",
    "        head_dim = dim//num_heads\n",
    "        scale = head_dim ** -0.5\n",
    "        B, N, C = x.shape\n",
    "        qkv_ = qkv(x).reshape(B, N, 3, num_heads, head_dim).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv_.unbind(0)\n",
    "        q, k = q_norm(q), k_norm(k)\n",
    "        q = q * scale\n",
    "        attn = q @ k.transpose(-2, -1)\n",
    "        attn = attn + attn_mask if attn_mask is not None else attn\n",
    "        attn = attn.softmax(-1)\n",
    "        attn = attn_drop(attn)\n",
    "        x = epsilon_lrp(torch.matmul, 1e-6, attention.detach(), v)\n",
    "        x = x.transpose(1, 2).reshape(B,N,C)\n",
    "        x = norm(x)\n",
    "        x = proj(x)\n",
    "        x = proj_drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6763720e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xformers-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
